[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joshua Murbarger",
    "section": "",
    "text": "I’m a candidate in the Master’s program in Geospatial Data Science at Temple University.\n\nThis is my portfolio.\nIt is under construction."
  },
  {
    "objectID": "blog/gee-post/index.html",
    "href": "blog/gee-post/index.html",
    "title": "Viz-a-day",
    "section": "",
    "text": "Some plots are trickier than they look. In order to hone my dataviz skills in matplotlib, I’ve been replicating interesting charts I see in the news. I’ve been noticing more horizontal stacked bar charts in articles on news sites. I’m guessing the horizontal construction plays better with smaller screens and, if the chart is presenting minimal information, like the answer to a survey question, it breaks up or grounds the columnar format nicely. Here’s an example from a recent publication from the Kaiser Family Foundation.\n\n\n\nOriginal\n\n\nUnfortunately, matplotlib doesn’t seem play nicely with legend labeling. I spent several hours trying to tweak different forms of this chart using different tutorials. My first attempt was the following:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ncategory_names = ['A lot', 'Some',\n                  'Not too much', 'Not at all']\ncategory_colors = [ '#001e36','#004a87', '#00b588', '#1a7563']\nresults = {\n    'Total Democratic women voters': [49, 33, 13, 5],\n    '18-29': [27, 47, 22, 4],\n    '30-49': [41, 36, 14, 9],\n    '50-64': [56, 26, 12, 6],\n    '65+': [66, 27, 7, 0]\n\n}\n\n\ndef survey(results, category_names):\n    \"\"\"\n    Parameters\n    ----------\n    results : dict\n        A mapping from question labels to a list of answers per category.\n        It is assumed all lists contain the same number of entries and that\n        it matches the length of *category_names*.\n    category_names : list of str\n        The category labels.\n    \"\"\"\n    labels = list(results.keys())\n\n    data = np.array(list(results.values()))\n    data_cum = data.cumsum(axis=1)\n#     category_colors = plt.colormaps['RdYlGn'](\n#         np.linspace(0.15, 0.85, data.shape[1]))\n\n    fig, ax = plt.subplots(figsize=(9.2, 5))\n    ax.invert_yaxis()\n    ax.xaxis.set_visible(False)\n    ax.set_xlim(0, np.sum(data, axis=1).max())\n\n    for i, (colname, color) in enumerate(zip(category_names, category_colors)):\n        widths = data[:, i]\n        starts = data_cum[:, i] - widths\n        rects = ax.barh(labels, widths, left=starts, height=0.5,\n                        label=colname, color=color)\n        \n\n        text_color = 'white'\n        ax.bar_label(rects, label_type='center', fmt = \"%.0f%%\", padding=-8, weight='bold', color=text_color)\n    ax.legend(ncols=len(category_names), bbox_to_anchor=(-.29, 1), loc='lower left', fontsize='small')\n    ax.text(x=-.09, y=1, s=\"How much, if at all, do you trust Vice President Kamala Harris to speak about abortion policy?\", transform=fig.transFigure, ha='left', fontsize=13, alpha=.8)\n    \n\n\n\nsurvey(results, category_names)\nplt.show()\nWhich yielded this.\n\n\n\nFirst attempt\n\n\nNext, I tried\nimport pandas as pd\n\n# dataframe\ndf = pd.DataFrame({'A lot': [49,27,41,56,66],\n                   'Some': [33,47,36,26,27],\n                   'Not too much': [13,22,14,12,7],\n                   'Not at all': [5,9,8,6,0]},\n                   index=['Total Democratic Women Voters', '18-29', '30-49', '50-64', '65+'])\n\n# get the totals for each row\ntotals = df.sum(axis=1)\n\n# calculate the percent for each row\npercent = df.div(totals, axis=0).mul(100).round(2)\n\n# create the plot\nax = percent.plot(kind='barh', stacked=True, figsize=(9, 5), color=['#001e36','#004a87', '#00b588', '#1a7563'], xticks=[])\n# move the legend\nax.legend(loc='upper left', ncol=4, frameon=False, bbox_to_anchor=(-.5, 1.1))\n\n# remove ticks\nax.tick_params(left=False, bottom=True)\n# remove all spines\nax.spines[['top', 'bottom', 'left', 'right']].set_visible(False)\n\n# iterate through each container\nfor c in ax.containers:\n    \n    # custom label calculates percent and add an empty string so 0 value bars don't have a number\n    labels = [f'{w:0.0f}%' if (w := v.get_width()) &gt; 0 else '' for v in c]\n    \n    # add annotations\n    ax.bar_label(c, labels=labels, weight='bold', label_type='center', padding=1, color='w')\nThis improved the labels on the bar, but didn’t help with the y-axis labels or legend mat size.\n\n\n\nSecond attempt\n\n\nIn my final matplotlib attempt, I tried to tweak the rc_params.\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ncategory_names = ['A lot', 'Some','Not too much', 'Not at all']\nresults = {'65+': [66, 27, 7, 0],\n           '50-64': [56, 26, 12, 6],\n           '30-49': [41, 36, 14, 9],\n           '18-29': [27, 47, 22, 4],\n           'White': [50,35,10,5],\n           'Hispanic': [42,31,20,7],\n           'Black': [51,25,18,6],\n           'Total Democratic Women Voters': [49, 33, 13, 5]}\n\n# setup dataframe using the dict provided in the OP\ndf = pd.DataFrame(results, index=category_names)\n# transpose df from the OP so Party is the in the columns and Ward is the index\ndft = df.T\n# plot\nax = df.T.plot.barh(stacked=True, figsize=(10, 6), color=['#001e36','#004a87', '#00b588', '#1a7563'])\n\nax.legend(loc=(-.365,1.03), ncol=4, frameon=False, markerscale=12)\nSMALL_SIZE = 8\nMEDIUM_SIZE = 10\nBIGGER_SIZE = 12\n\nplt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\nplt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\nplt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\nplt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\nplt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\nplt.rcParams['xtick.top'] = plt.rcParams['xtick.labeltop'] = False\nax.set_yticklabels(results.keys(), ha = 'left')              # Set horizontal alignment to left\nax.yaxis.set_tick_params(pad=200,            # Pad tick labels so they don't go over y-axis\n                         labelsize=11,       # Set label size\n                         bottom=False, top=False)       # Set no ticks on bottom/left\n\n# annotations:\nfor c in ax.containers:\n    \n    # format the number of decimal places and replace 0 with an empty string\n    labels = [f'{w:.0f}%' if (w := v.get_width()) &gt; 0 else '' for v in c ]\n    \n    ax.bar_label(c, labels=labels,label_type='center', color='w', weight='bold')\nWhich put the y-axis labels where I wanted, but I still couldn’t figure out the mat changes.\n\n\n\nThird attempt\n\n\n\nI finally gave up and tried using Flourish, a dataviz product. I wasn’t familiar with it, but going down the rabbit hole looking for solutions, I found it recommended by an Al-Jazeera datalab journalist. Here’s the product.\n\n\n\nUsing Flourish\n\n\n\nLater, I’ll see if I can learn more fixing those legend values.\n\n\n\nOriginal\nFirst attempt\nSecond attempt\nThird attempt\nUsing Flourish"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "",
    "section": "",
    "text": "Viz-a-day-2\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nJoshua Murbarger\n\n\n\n\n\n\n\n\n\n\n\n\nViz-a-day\n\n\n\n\n\n\n\n\n\n\n\nJul 24, 2024\n\n\nJoshua Murbarger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#transmission-line-inspector",
    "href": "projects.html#transmission-line-inspector",
    "title": "",
    "section": "Transmission Line Inspector",
    "text": "Transmission Line Inspector\n\n\nI built a tool to visualize potential tree strike areas and inspect tree health along high-voltage power lines. The tool employs 360° equirectangular imagery displayed via ESRI’s new Oriented Imagery viewer in ArcGIS Online. Trees identified as potential hazards can be examined by the client from multiple viewpoints in order to ascertain whether additional field inspection is warranted. - link to youtube demo -"
  },
  {
    "objectID": "projects.html#redistricting-plan-scorer-to-compare-compactness-contiguity-partisan-fairness-and-population-equality",
    "href": "projects.html#redistricting-plan-scorer-to-compare-compactness-contiguity-partisan-fairness-and-population-equality",
    "title": "",
    "section": "Redistricting Plan Scorer to Compare Compactness, Contiguity, Partisan Fairness, and Population Equality",
    "text": "Redistricting Plan Scorer to Compare Compactness, Contiguity, Partisan Fairness, and Population Equality\n\n\n\n\n\n\nIn GIS App Development, our two-person team built a tool to score proposed congressional redistricting plans on several state legislature and Constitutionally-mandated criteria, including population equality, compactness, and partisan fairness. I coded the GUI in pyQT5 and was responsible for the partisan fairness tests."
  },
  {
    "objectID": "projects.html#analysis-of-atmospheric-river-effects-in-california-2023-using-landsat-and-sentinel-1",
    "href": "projects.html#analysis-of-atmospheric-river-effects-in-california-2023-using-landsat-and-sentinel-1",
    "title": "",
    "section": "Analysis of Atmospheric River Effects in California 2023 Using LANDSAT and Sentinel-1",
    "text": "Analysis of Atmospheric River Effects in California 2023 Using LANDSAT and Sentinel-1\n\n\nI studied the effects of an “atmospheric river” in early 2023 that left at least 23 people dead in California. The analysis was conducted using Python, geemap, and jupyter notebook. Normalized Difference Water Index (NDWI) using LANDSAT imagery and Synthetic Aperture Radar (SAR) data from Sentinel-1 were used to calculate standing water left by the event."
  },
  {
    "objectID": "projects.html#machine-learning-land-use-classification-in-scikit-learn",
    "href": "projects.html#machine-learning-land-use-classification-in-scikit-learn",
    "title": "",
    "section": "Machine Learning Land-use Classification in scikit-learn",
    "text": "Machine Learning Land-use Classification in scikit-learn\n\n\n\n\n\n\nI created satellite imagery labels and and trained a machine learning model to classify land use in Baltimore. In this first iteration, the goal was to distinguish between high and medium density residential housing."
  },
  {
    "objectID": "projects.html#using-building-renovation-permit-applications-as-leading-indicators-for-property-crimes",
    "href": "projects.html#using-building-renovation-permit-applications-as-leading-indicators-for-property-crimes",
    "title": "",
    "section": "Using Building Renovation Permit Applications as Leading Indicators for Property Crimes",
    "text": "Using Building Renovation Permit Applications as Leading Indicators for Property Crimes\n\n\nIn another analysis, I looked for correlations between the number of building renovation permits filed with the Bureau of Licenses and Inspections and the frequency of reported property crimes in several South Philadelphia neighborhoods. I was interested to see whether permits could be used as a leading indicator."
  },
  {
    "objectID": "projects.html#predicting-the-alabama-state-constitutional-amendment-vote",
    "href": "projects.html#predicting-the-alabama-state-constitutional-amendment-vote",
    "title": "",
    "section": "Predicting the Alabama State Constitutional Amendment Vote",
    "text": "Predicting the Alabama State Constitutional Amendment Vote\n\n\n\n\n\n\nIn another project, I built a multivariable regression model in R to predict the election outcome of a ballot initiative that amended the Alabama State Constitution."
  },
  {
    "objectID": "projects.html#demonstrating-k-means-clustering-with-behavioral-risk-factor-surveillance-system-and-cdc-gun-death-data",
    "href": "projects.html#demonstrating-k-means-clustering-with-behavioral-risk-factor-surveillance-system-and-cdc-gun-death-data",
    "title": "",
    "section": "Demonstrating K-Means Clustering with Behavioral Risk Factor Surveillance System and CDC Gun Death Data",
    "text": "Demonstrating K-Means Clustering with Behavioral Risk Factor Surveillance System and CDC Gun Death Data\n\n\nI demonstrated the implementation and optimization of K-Means clustering using gun ownership data from BRFSS and CDC gun death data. Rates of gun ownership closely correlate with gun deaths. Pictured are 4 clusters of states. An interesting follow-up question is whether the clusters have similar levels of firearm regulation."
  },
  {
    "objectID": "blog/day2-post/index.html",
    "href": "blog/day2-post/index.html",
    "title": "Viz-a-day-2",
    "section": "",
    "text": "Day two was another horizontal percentage stacked bar. They’re trickier than they look. This one is from the NYT.\n\n\n\nOriginal\n\n\nHere’s my code. Pretty close. I need to work on font matching.\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ny = 0\nvery = 78\nsome = 11\nnots = 1\ndont = 10\nfig, ax = plt.subplots()\nax.broken_barh([(y, very), (very, very+some), (very+some, very+some+nots), (very+some+nots, very+some+nots+dont)], [10, 9], facecolors=('#006b91', '#529cb9', '#f7904d','#ededed'), edgecolor='white')\nax.set_ylim(-40, 50)\nax.set_xlim(0, 100)\nax.spines['left'].set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.set_yticks([])\nax.set_xticks([])\n\nax.text(1, 11.5, \"78%\", fontsize=10, color='w', weight='bold')\nax.text(79, 11.5, \"11%\", fontsize=10, color='w', weight='bold')\n# ax.text((very+some+nots)+2, 14.5, \"1%\", fontsize=8)\nax.text(91, 11.5, \"10%\", fontsize=10, weight='bold')\nax.text(0, 20, \"Very satisfied\", fontsize=7)\nax.text(79, 20, \"Somewhat\\nsatisfied\", fontsize=7 )\nax.text(85, 7, \"Not satisfied\", fontsize=7)\nax.text(89, 9, \"|\", fontsize=4, weight='bold')\nax.text(91, 20, \"Don\\'t\\nknow\", fontsize=7)\nax.text(0, 27, \"Regardless of whom you prefer to be the nominee, how satisfied would you be\\nwith Kamala Harris as the nominee?\", fontsize=8, weight='bold')\n\nplt.show()\nWhich yielded this.\n\n\n\nFirst attempt\n\n\n\n\n\nOriginal\nFirst attempt"
  },
  {
    "objectID": "RuncibleSpoonClassifier.html",
    "href": "RuncibleSpoonClassifier.html",
    "title": "",
    "section": "",
    "text": "#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 719.8/719.8 kB 5.2 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 547.8/547.8 kB 8.0 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 MB 6.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 5.7 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 kB 3.5 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 3.9 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 5.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 36.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.3/21.3 MB 35.4 MB/s eta 0:00:00\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pyarrow&lt;15.0.0a0,&gt;=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\nibis-framework 8.0.0 requires pyarrow&lt;16,&gt;=2, but you have pyarrow 16.1.0 which is incompatible.\nMounted at /content/gdrive\n\n\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n\n\nkey = os.environ.get('AZURE_SEARCH_KEY', 'b9de02b731604e1693dfd9e232a240e9')\n\n\n# results = search_images_bing(key, 'grizzly bear')\n# ims = results.attrgot('contentUrl')\n# len(ims)\n\n\nutensil_types = 'fork','spoon','runcible spoon'\npath = Path('utensils')\n\n\nif not path.exists():\n    path.mkdir()\n    for o in utensil_types:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True)\n        results = search_images_bing(key, f'{o}')\n        download_images(dest, urls=results.attrgot('contentUrl'))\n\n\nfns = get_image_files(path)\nfns\n\n(#410) [Path('utensils/runcible spoon/397c45f2-2dbb-44bc-b856-7284eac1ab9f.jpg'),Path('utensils/runcible spoon/11f58ab2-31fc-4835-9c10-ddde90f7ccd7.jpg'),Path('utensils/runcible spoon/a11a727e-d55e-4f86-8796-c3000052dc02.jpg'),Path('utensils/runcible spoon/61a0afc4-90c4-4f90-93cc-d34e9179e4a8.jpg'),Path('utensils/runcible spoon/33c3ed2e-9720-4c8e-a27f-531ee1a2c2a1.JPG'),Path('utensils/runcible spoon/6da601a9-e229-494e-a358-51c1ab2b6795.jpg'),Path('utensils/runcible spoon/76994c76-fb43-4d79-94d2-4d098fc139a6.JPG'),Path('utensils/runcible spoon/27b64b1c-77a8-402a-91fc-61d3cb0f3bcf.jpg'),Path('utensils/runcible spoon/e3776814-02a9-460b-a545-806e6469c4fe.jpg'),Path('utensils/runcible spoon/d4834aaf-18f7-47cd-838f-1a562b5b16d8.jpg')...]\n\n\n\nfailed = verify_images(fns)\nfailed\n\n(#21) [Path('utensils/runcible spoon/ff76183d-8c9b-484d-b91f-31567eb60132.jpg'),Path('utensils/runcible spoon/c3629a0f-7d36-41aa-b0fb-dabad8454bd5.jpg'),Path('utensils/fork/47bd8f48-3b57-44b1-b8c7-bb3945e06f8f.jpg'),Path('utensils/fork/b5878435-8c00-4ba7-bf5a-88bed767b17e.jpg'),Path('utensils/fork/8a716d93-7b99-41eb-98d0-653e6deb0da1.jpg'),Path('utensils/spoon/427c9456-4b92-474a-a840-fde8eab6a6e2.jpg'),Path('utensils/spoon/69c615b6-4ec8-4f4c-a8fd-ccb3822b86cc.jpg'),Path('utensils/spoon/58ac33ba-ad32-4f00-b2db-963e6a671ea2.png'),Path('utensils/spoon/b1c6b2b3-078d-4870-ae41-646f9fe6ce29.jpg'),Path('utensils/spoon/38568c4e-ac5d-4280-949e-68d714661446.jpg')...]\n\n\n\nfailed.map(Path.unlink);\n\n\nclass DataLoaders(GetAttr):\n    def __init__(self, *loaders): self.loaders = loaders\n    def __getitem__(self, i): return self.loaders[i]\n    train,valid = add_props(lambda i,self: self[i])\n\n\nutensils = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\n\nutensils = utensils.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\ndls = utensils.dataloaders(path)\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.661255\n0.811002\n0.295775\n01:21\n\n\n\n\n\n\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.000136\n0.561229\n0.225352\n01:51\n\n\n1\n0.878370\n0.491615\n0.197183\n01:48\n\n\n2\n0.724084\n0.470758\n0.169014\n01:47\n\n\n3\n0.634474\n0.466497\n0.169014\n01:50\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n/usr/local/lib/python3.10/dist-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n  warn(\"Your generator is empty.\")\n\n\nValueError: not enough values to unpack (expected 4, got 3)\n\n\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\n\nFileNotFoundError: [Errno 2] No such file or directory: 'utensils/spoon/75a054e8-02ad-456c-893e-fd8124c9705b.jpg'\n\n\n\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n\nError: Destination path 'utensils/spoon/ff99cdb3-57b0-43f8-a37a-0a957fc1636a.jpg' already exists\n\n\n\nlearn.export()\n\n\nlearn_inf = load_learner('export.pkl')\n\n\nlearn_inf = load_learner(path/'export.pkl')\n\nFileNotFoundError: [Errno 2] No such file or directory: 'utensils/export.pkl'\n\n\n\nbtn_upload = widgets.FileUpload()\nbtn_upload\n\n\n\n\n\nimg = PILImage.create(btn_upload.data[-1])\n\n\nout_pl = widgets.Output()\nout_pl.clear_output()\nwith out_pl: display(img.to_thumb(128,128))\nout_pl\n\n\n\n\n\npred,pred_idx,probs = learn_inf.predict(img)\n\n\n\n\n\n\n\n\n\nlbl_pred = widgets.Label()\nlbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\nlbl_pred"
  }
]