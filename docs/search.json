[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joshua Murbarger",
    "section": "",
    "text": "I’m a candidate in the Master’s program in Geospatial Data Science at Temple University.\n\nThis is my portfolio.\nIt is under construction."
  },
  {
    "objectID": "blog/gee-post/index.html",
    "href": "blog/gee-post/index.html",
    "title": "Sprint 1 Recap",
    "section": "",
    "text": "My capstone project involves automating the essential components of a forestry data start-up’s GIS pipeline. The pipeline breaks down into three major stages. The first stage of the pipeline involves formatting client-provided data during the intake process. Clients usually provide a shapefile of forest stands. The shapefile usually includes unique identifiers the client uses to track age and development of timber assests. It may be provided in a state plane coordinate system. It must be reprojected to the World Geodetic System EPSG:4326 and be formatted with several startup specific fields to faciliate data collection and processing. In most cases, the next step is running a plot sampling script to randomly select sample plots in the stand according to the customers sampling methodology. Occasionally, clients provide an additional pointfile of centerpoints for plots they wish to be use for sampling. The basic workflow is to copy the customer data and reproject the copies to EPSG:4326, create a geopackage layer, add field values individually via a field calculator in QGIS, map client-named fields to their internal field schema by hand and use the field calculator to populate the values, run the sampling algorithm, create new fields in the newly-formed plots layer, bundle all of the new layers into a single geopackage and upload them to a designated folder on AWS.\nThe initial days of Sprint 1 were spent finishing up the first draft of the Stem Map script to include sharing and group creation. The bulk of the work was spent on the development of the Field Map script."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "",
    "section": "",
    "text": "Sprint 1 Recap\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nJoshua Murbarger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#redistricting-plan-scorer-to-compare-compactness-contiguity-partisan-fairness-and-population-equality",
    "href": "projects.html#redistricting-plan-scorer-to-compare-compactness-contiguity-partisan-fairness-and-population-equality",
    "title": "",
    "section": "Redistricting Plan Scorer to Compare Compactness, Contiguity, Partisan Fairness, and Population Equality",
    "text": "Redistricting Plan Scorer to Compare Compactness, Contiguity, Partisan Fairness, and Population Equality\n\n\n\n\n\n\nOur team built a tool to score proposed congressional redistricting plans on several state legislature and Constitutionally-mandated criteria, including population equality, compactness, and partisan fairness. I coded the GUI in pyQT and was responsible for the partisan fairness tests. - link -"
  },
  {
    "objectID": "projects.html#analysis-of-atmospheric-river-effects-in-california-2023-using-landsat-and-sentinel-1",
    "href": "projects.html#analysis-of-atmospheric-river-effects-in-california-2023-using-landsat-and-sentinel-1",
    "title": "",
    "section": "Analysis of Atmospheric River Effects in California 2023 Using LANDSAT and Sentinel-1",
    "text": "Analysis of Atmospheric River Effects in California 2023 Using LANDSAT and Sentinel-1\n\n\nI studied the effects of an “atmospheric river” in early 2023 that left at least 23 people dead in California. The analysis was conducted using python, geemap, and jupyter notebook. Normalized Difference Water Index (NDWI) using LANDSAT imagery and Synthetic Aperture Radar (SAR) data from Sentinel-1 were used to calculate standing water left by the event. - link -"
  },
  {
    "objectID": "projects.html#machine-learning-land-use-classification-in-scikit-learn",
    "href": "projects.html#machine-learning-land-use-classification-in-scikit-learn",
    "title": "",
    "section": "Machine Learning Land-use Classification in scikit-learn",
    "text": "Machine Learning Land-use Classification in scikit-learn\n\n\n\n\n\n\nI created satellite imagery labels and and trained a machine learning model to classify land use in Baltimore. In this first iteration, the goal was to distinguish between high and medium density residential housing. - link -"
  },
  {
    "objectID": "projects.html#using-building-renovation-permit-applications-as-leading-indicators-for-property-crimes",
    "href": "projects.html#using-building-renovation-permit-applications-as-leading-indicators-for-property-crimes",
    "title": "",
    "section": "Using Building Renovation Permit Applications as Leading Indicators for Property Crimes",
    "text": "Using Building Renovation Permit Applications as Leading Indicators for Property Crimes\n\n\nIn another analysis, I looked for correlations between the number of building renovation permits filed with the Bureau of Licenses and Inspections and the frequency of reported property crimes in several South Philadelphia neighborhoods. I was interested to see whether permits could be used as a leading indicator. - link -"
  },
  {
    "objectID": "projects.html#predicting-the-alabama-state-constitutional-amendment-vote",
    "href": "projects.html#predicting-the-alabama-state-constitutional-amendment-vote",
    "title": "",
    "section": "Predicting the Alabama State Constitutional Amendment Vote",
    "text": "Predicting the Alabama State Constitutional Amendment Vote\n\n\n\n\n\n\nIn another project, I built a multivariable regression model in R to predict the election outcome of a ballot initiative that amended the Alabama State Constitution. - link -"
  },
  {
    "objectID": "projects.html#demonstrating-k-means-clustering-with-behavioral-risk-factor-surveillance-system-and-cdc-gun-death-data",
    "href": "projects.html#demonstrating-k-means-clustering-with-behavioral-risk-factor-surveillance-system-and-cdc-gun-death-data",
    "title": "",
    "section": "Demonstrating K-Means Clustering with Behavioral Risk Factor Surveillance System and CDC Gun Death Data",
    "text": "Demonstrating K-Means Clustering with Behavioral Risk Factor Surveillance System and CDC Gun Death Data\n\n\nAs part of a student-led tutorial, I demonstrated the implementation and optimization of K-Means clustering using BRFSS and CDC gun death data. Rates of gun ownership closely correlate with gun deaths.Pictured are 4 clusters of states. An interesting follow-up question is whether the clusters have similar levels of firearm regulation. - link -"
  }
]